{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "667de570-4cc1-4e57-9212-3acdb5730c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for name in dir():\n",
    "    if not name.startswith('_'):\n",
    "        del globals()[name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "908546e2-1184-42b7-8b0e-d2b72ab62cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import PIL\n",
    "import numpy as np # linear algebra\n",
    "import matplotlib.pyplot as plt # Ploting the diagrams\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "import math\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "\n",
    "import os\n",
    "from os import listdir\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt # Ploting the diagrams\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from tensorflow.keras.utils import load_img\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from tensorflow.keras import models\n",
    "import random\n",
    "from keras.models import model_from_json\n",
    "import pandas as pd\n",
    "tf.random.set_seed(333)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac3f5cad-68b3-481d-8965-d4e3e5fc5266",
   "metadata": {},
   "source": [
    "## 1. Initialize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8dc7781b-397b-406a-841d-f3fdc4d4e574",
   "metadata": {},
   "outputs": [],
   "source": [
    "clients = 5\n",
    "rounds = 12\n",
    "splits = (clients+1)*rounds+1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f61c106d-efd9-4642-b483-516fb352fce8",
   "metadata": {},
   "source": [
    "## 2. Loading dataset in memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3c82101a-9ebb-426a-add1-4b8c31830599",
   "metadata": {},
   "outputs": [],
   "source": [
    "def genImageList(l):\n",
    "    return list(filter(lambda i: i.split(\".\")[-1] in [\"png\",\"jpg\",\"jpeg\"], l))\n",
    "def genDf(images,labels):\n",
    "    df= pd.DataFrame(images,columns=[\"Image\"])\n",
    "    df[\"Class\"] = labels\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66b98e16-3930-4028-9b48-9e36181a4d69",
   "metadata": {},
   "source": [
    "## 2.1 Generating Global Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "daab15e7-77f3-4326-96cf-00dc3fc0b35f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting all FileNames\n",
    "gMaskPath = r'Test/Mask/'\n",
    "gNoMaskPath = r'Test/NoMask/'\n",
    "gMaskImages = genImageList([gMaskPath+i for i in os.listdir(gMaskPath)])\n",
    "gMaskLabels = np.zeros(len(gMaskImages))\n",
    "gNoMaskImages = genImageList([gNoMaskPath+i for i in os.listdir(gNoMaskPath)])\n",
    "gNoMaskLabels = np.ones(len(gNoMaskImages))\n",
    "\n",
    "gMaskDf = genDf(gMaskImages,gMaskLabels)\n",
    "gNoMaskDf = genDf(gNoMaskImages,gNoMaskLabels)\n",
    "\n",
    "gDf = pd.DataFrame(shuffle(pd.concat([gMaskDf,gNoMaskDf])),columns=gMaskDf.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b7e5429-d80c-4fc1-b19b-08fa1d3d0791",
   "metadata": {},
   "source": [
    "## 3. Stratified Kfolds Custom Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "070a80eb-6ff0-46c5-8f7b-7bab4747112c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def genKSplitDf(df,splits):\n",
    "    index = np.array_split(shuffle(df.index,random_state=3333),splits)    \n",
    "    folds = []\n",
    "    for i in range(splits):\n",
    "        folds.append(df.filter(items = index[i], axis=0))\n",
    "    return folds\n",
    "def mergeDf(df1,df2,splits):\n",
    "    columns = df1[0].columns\n",
    "    folds = []\n",
    "    for i in range(splits):\n",
    "        folds.append(pd.DataFrame(shuffle(pd.concat([df1[i],df2[i]]),random_state=3333),columns=columns)) \n",
    "    return folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "16b06cd9-6aae-4d23-b8cc-e7dbf0138d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "maskFolds = genKSplitDf(gMaskDf,splits)\n",
    "noMaskFolds = genKSplitDf(gNoMaskDf,splits)\n",
    "folds = mergeDf(maskFolds,noMaskFolds,splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "855d6bd9-5d2c-42aa-bd86-e4daf96e5147",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "73"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(folds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c352e30e-851c-410f-936c-495b46cbf808",
   "metadata": {},
   "source": [
    "## 4. Simulation Setup for Federated Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "010aa12c-f386-4248-a2ef-f68d2a8b681a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history(history):\n",
    "    \n",
    "    fig, ax = plt.subplots(1, 1,figsize=(5,5))\n",
    "    ax.plot(history.history['accuracy'])\n",
    "    ax.plot(history.history['val_accuracy'])\n",
    "    ax.set_title('Model Accuracy')\n",
    "    ax.set(xlabel='Epoch',ylabel='Accuracy')\n",
    "    ax.legend(['train', 'test'], loc='upper left')\n",
    "\n",
    "def createModel(shape=(100,100,3)):\n",
    "    tf.random.set_seed(3333)\n",
    "    model = Sequential()\n",
    "    model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=shape))\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "    model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "    model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dropout(0.2))\n",
    "    model.add(layers.Dense(64, activation='relu'))\n",
    "    model.add(layers.Dropout(0.2))\n",
    "    model.add(layers.Dense(1, activation='sigmoid'))\n",
    "    model.compile(optimizer='adam',\n",
    "                  # loss='kl_divergence',\n",
    "                  loss = 'binary_crossentropy',\n",
    "                  metrics=[tf.keras.metrics.Recall(),tf.keras.metrics.Precision(),tf.keras.metrics.AUC(\n",
    "        num_thresholds=200, curve='ROC',\n",
    "        summation_method='interpolation', name=None, dtype=None,\n",
    "        thresholds=None, multi_label=False, label_weights=None\n",
    "    ),'accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "def genModel(df,model,name):\n",
    "    \n",
    "    x,y = df[\"Image\"],df[\"Class\"]\n",
    "    data = []\n",
    "    size = 100\n",
    "    \n",
    "    for img_path in x:\n",
    "        image = load_img(img_path, target_size=(size, size))\n",
    "        image = img_to_array(image)\n",
    "        image = image/255\n",
    "        data.append(image)\n",
    "\n",
    "    data = np.array(data, dtype=\"float32\")\n",
    "    labels = np.array(y).reshape([-1,1])\n",
    "    \n",
    "    # trainx,testx,trainy,testy = train_test_split(data,labels,random_state=333,test_size=0.3)\n",
    "    \n",
    "    history = model.fit(data, labels, epochs=10,validation_split=0.2,verbose=0)\n",
    "    acc = []\n",
    "    loss = []\n",
    "    \n",
    "    for i,j in zip(history.history[\"loss\"],history.history[\"accuracy\"]):\n",
    "        acc.append(j)\n",
    "        loss.append(i)\n",
    "    \n",
    "    # plot_history(history,name)\n",
    "    return model,acc,loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6128329f-7aba-48eb-aa03-b9e73e9696e9",
   "metadata": {},
   "source": [
    "## 4.1 Initializing Global Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f7edd170-8473-4083-8cb1-9285f56b5136",
   "metadata": {},
   "outputs": [],
   "source": [
    "globalModel,initAcc,initLoss = genModel(folds.pop(),createModel(),\"Init\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d2880c6-5d04-4610-bda4-0f1452b40ead",
   "metadata": {},
   "source": [
    "## Initializing Cleint Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6d57804d-211f-4d88-8893-e508758aa72d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def genClientModel(globalModel,name):\n",
    "    model = createModel()\n",
    "    model.set_weights(globalModel.get_weights())\n",
    "    model._name = name\n",
    "    return model\n",
    "\n",
    "def preprocessWeights(weights,acc):\n",
    "    newWeights = []\n",
    "    for i,j in zip(weights,acc):\n",
    "        temp = []\n",
    "        for w in i:\n",
    "            temp.append(w*j)\n",
    "        newWeights.append(temp)\n",
    "    return newWeights\n",
    "\n",
    "def avergeWeights(w):\n",
    "    acc = np.array(w[0],dtype=object)\n",
    "    for i in range(1,len(w)):\n",
    "        acc = acc + np.array(w[i],dtype=object)\n",
    "    acc = acc/len(w)\n",
    "    return [np.array(i) for i in acc.tolist()]\n",
    "    \n",
    "def updateWeights(newWeights,model,layers):\n",
    "    upModels = []\n",
    "    \n",
    "    for m in model:\n",
    "        updated = []\n",
    "        \n",
    "        w = m.get_weights()\n",
    "        \n",
    "        for l in range(len(w)):\n",
    "            if l in layers:\n",
    "                updated.append(newWeights[l])\n",
    "            else:\n",
    "                updated.append(w[l])\n",
    "        \n",
    "        m.set_weights(updated)\n",
    "        upModels.append(m)\n",
    "        \n",
    "    return upModels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4a71f0ba-384d-40a9-af7a-f710650946a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Based on our model\n",
    "shallow = [0,1,2,3,4,5]\n",
    "deep = [6,7,8,9]\n",
    "allLayers =  shallow + deep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "348d4976-7332-461b-a720-a0adcfdb3b9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allLayers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c1231d57-eedd-48de-829b-96d129bab9a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "clientModels = [genClientModel(globalModel,\"Client_\"+str(i)) for i in range(clients)]\n",
    "modelRes = np.zeros(clients).tolist()\n",
    "\n",
    "clientRes = {}\n",
    "clientLossHist = {}\n",
    "clientAccHist = {}\n",
    "for c in range(clients):\n",
    "    clientRes[c] = []\n",
    "    clientLossHist[c] = initLoss[:]\n",
    "    clientAccHist[c] =  initAcc[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fcdaecb9-a840-4343-aaa8-62e117a8e0a3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round -  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yashb\\anaconda3\\envs\\goku\\lib\\site-packages\\PIL\\Image.py:976: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round -  2\n",
      "Round -  3\n",
      "Round -  4\n",
      "Round -  5\n",
      "Round -  6\n",
      "Round -  7\n",
      "Round -  8\n",
      "Round -  9\n",
      "Round -  10\n",
      "Round -  11\n",
      "Round -  12\n"
     ]
    }
   ],
   "source": [
    "for i in range(rounds):\n",
    "    print(\"Round - \",i+1)\n",
    "    \n",
    "    for c in range(clients):\n",
    "        clientModels[c],acc,loss = genModel(folds.pop(),clientModels[c],\"C\"+str(c)+\"_\"+str(i)) \n",
    "        clientLossHist[c].extend(loss[:])\n",
    "        clientAccHist[c].extend(acc[:])  \n",
    "            \n",
    "    w = preprocessWeights([model.get_weights() for model in clientModels],[1 for res in modelRes])\n",
    "    avgW = avergeWeights(w)\n",
    "\n",
    "    clientModels = updateWeights(avgW,clientModels,allLayers)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b5b55bc9-2371-4a16-945c-77c7d4913e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "central,acc,loss = genModel(gDf,createModel(),\"\")\n",
    "central.save(\"model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d5ece1fc-8543-4063-850a-b27342760aa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def genXY(df):\n",
    "    x,y = df[\"Image\"],df[\"Class\"]\n",
    "    data = []\n",
    "    size = 100\n",
    "    \n",
    "    for img_path in x:\n",
    "        image = load_img(img_path, target_size=(size, size))\n",
    "        image = img_to_array(image)\n",
    "        image = image/255\n",
    "        data.append(image)\n",
    "    data = np.array(data, dtype=\"float32\")\n",
    "    labels = np.array(y).reshape([-1,1])\n",
    "    return data,labels\n",
    "gMaskPath = r'Global/Mask/'\n",
    "gNoMaskPath = r'Global/NoMask/'\n",
    "gMaskImages = genImageList([gMaskPath+i for i in os.listdir(gMaskPath)])\n",
    "gMaskLabels = np.zeros(len(gMaskImages))\n",
    "gNoMaskImages = genImageList([gNoMaskPath+i for i in os.listdir(gNoMaskPath)])\n",
    "gNoMaskLabels = np.ones(len(gNoMaskImages))\n",
    "\n",
    "gMaskDf = genDf(gMaskImages,gMaskLabels)\n",
    "gNoMaskDf = genDf(gNoMaskImages,gNoMaskLabels)\n",
    "\n",
    "tDf = pd.DataFrame(shuffle(pd.concat([gMaskDf,gNoMaskDf])),columns=gMaskDf.columns)\n",
    "\n",
    "tx,ty = genXY(tDf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5fe88e9e-972c-401c-b42e-5d74059f3741",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "188/188 [==============================] - 1s 7ms/step - loss: 0.3978 - recall_1: 0.9850 - precision_1: 0.8819 - auc_1: 0.9598 - accuracy: 0.9265\n",
      "188/188 [==============================] - 1s 7ms/step - loss: 0.3978 - recall_2: 0.9850 - precision_2: 0.8819 - auc_2: 0.9598 - accuracy: 0.9265\n",
      "188/188 [==============================] - 1s 6ms/step - loss: 0.3978 - recall_3: 0.9850 - precision_3: 0.8819 - auc_3: 0.9598 - accuracy: 0.9265\n",
      "188/188 [==============================] - 1s 6ms/step - loss: 0.3978 - recall_4: 0.9850 - precision_4: 0.8819 - auc_4: 0.9598 - accuracy: 0.9265\n",
      "188/188 [==============================] - 1s 6ms/step - loss: 0.3978 - recall_5: 0.9850 - precision_5: 0.8819 - auc_5: 0.9598 - accuracy: 0.9265\n"
     ]
    }
   ],
   "source": [
    "res = []\n",
    "for c in range(clients):\n",
    "    res.append(clientModels[c].evaluate(tx,ty)[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e39eb178-0766-4b8e-948f-7ffc66e9c29f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "df[\"Testing Results\"] = res\n",
    "df.to_csv(\"Results/v.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dfd34759-a8b7-4541-9a9a-e000346bc543",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfL = pd.DataFrame()\n",
    "for k in clientLossHist.keys():\n",
    "    dfL[\"Client \"+ str(k)] = clientLossHist[k]\n",
    "dfL.to_csv(\"vLoss.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c2b9004d-119b-4739-b2f1-8471dbdbcddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "for k in clientLossHist.keys():\n",
    "    df[\"Client \"+ str(k)] = clientAccHist[k]\n",
    "df.to_csv(\"Results/vAcc.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fe19d52c-d3ac-4456-94a8-b0e1897aab53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "188/188 [==============================] - 1s 6ms/step - loss: 0.2186 - recall_6: 0.9803 - precision_6: 0.9206 - auc_6: 0.9801 - accuracy: 0.9479\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.21864436566829681,\n",
       " 0.9802939295768738,\n",
       " 0.9206398725509644,\n",
       " 0.9800945520401001,\n",
       " 0.9478957653045654]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "central.evaluate(tx,ty)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
